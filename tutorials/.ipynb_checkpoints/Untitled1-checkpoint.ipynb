{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844fc226-e208-4934-bf2f-666cb8fb63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778933333333332\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "root=\"/nfsmount/shuai.lyu/workspace/outputs/exp4\"\n",
    "\n",
    "vals=[]\n",
    "\n",
    "import os \n",
    "\n",
    "logdirs=  [   os.path.join(root,dname,\"log\")  for dname in  os.listdir(root) if os.path.isdir(os.path.join(root,dname,\"log\"))]\n",
    "\n",
    "for logdir in logdirs:\n",
    "    logdir=os.path.join(logdir,os.listdir(logdir)[0])\n",
    "    print(logdir)\n",
    "    tb=TBLoader(logdir)\n",
    "    val=tb.get_vals(\"epo_density_roc_auc\")[-1] #epo_class_roc_auc\n",
    "    vals.append(val)\n",
    "    \n",
    "print(np.mean(vals))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee9448-60cf-40c5-9498-01daade703d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:00<00:00, 789144.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "class Hook:\n",
    "    def before_train(self) -> None:\n",
    "        \"\"\"Called before the first iteration.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_train(self) -> None:\n",
    "        \"\"\"Called after the last iteration.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_epoch(self) -> None:\n",
    "        \"\"\"Called before each epoch.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_epoch(self) -> None:\n",
    "        \"\"\"Called after each epoch.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_step(self) -> None:\n",
    "        \"\"\"Called before each iteration.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_step(self) -> None:\n",
    "        \"\"\"Called before each iteration.\"\"\"\n",
    "        pass\n",
    "class Trainer(object):\n",
    "       \n",
    "    def __init__(self):\n",
    "        self._hooks = [] \n",
    "        self.epo=0\n",
    "        self.epo_step=0\n",
    "        \n",
    "    def register_hooks(self, hooks):\n",
    "        # 将钩子注册到trainer中，实际上就是放到trainer的_hooks列表里以便后续调用\n",
    "        \n",
    "        \n",
    "        if isinstance(hooks,Hook):\n",
    "            hooks=[hooks]\n",
    "        for hook in hooks:\n",
    "            # 这里为每个钩子创建一个类变量，指向当前trainer。\n",
    "            # 这样就可以访问trainer内部的model、optimizer、epoch，iter等。\n",
    "            assert(isinstance(hook,Hook))\n",
    "            hook.trainer = self\n",
    "            self._hooks.append(hook)\n",
    "            \n",
    "    def before_train(self):\n",
    "        for hook in self._hooks:\n",
    "            hook.before_train()   \n",
    "    def after_train(self):   \n",
    "        for hook in self._hooks:\n",
    "            hook.after_train()    \n",
    "    def before_epoch(self):\n",
    "        for hook in self._hooks:\n",
    "            hook.before_epoch()  \n",
    "    def after_epoch(self):\n",
    "        for hook in self._hooks:\n",
    "            hook.after_epoch()  \n",
    "    def before_step(self):\n",
    "        for hook in self._hooks:\n",
    "            hook.before_step()  \n",
    "    def after_step(self):      \n",
    "        for hook in self._hooks:\n",
    "            hook.after_step()   \n",
    "    def train_step(self):\n",
    "        pass\n",
    "\n",
    "    def run_train(self,epoches=None,num_steps_per_epoch=None):\n",
    "        \n",
    "        self.epoches=epoches\n",
    "        self.num_steps_per_epoch=num_steps_per_epoch\n",
    "        \n",
    "        #0. before train\n",
    "        self.before_train()\n",
    "\n",
    "        for step in tqdm(range(self.epoches*self.num_steps_per_epoch)):\n",
    "            \n",
    "            self.epo = math.ceil((step+1) / self.num_steps_per_epoch)\n",
    "            self.epo_step=step%self.num_steps_per_epoch+1\n",
    "            #2. train loop\n",
    "            if self.epo_step==1: self.before_epoch()\n",
    "            \n",
    "            self.before_step()\n",
    "            \n",
    "            self.train_step()\n",
    "            \n",
    "            self.after_step()\n",
    "\n",
    "             #the last iteration within a epoch \n",
    "            if self.epo_step==self.num_steps_per_epoch:  self.after_epoch()\n",
    "        self.after_train()   \n",
    "                \n",
    "class CheckpointHook(Hook):\n",
    "    def after_train(self):\n",
    "        # self.trainer是在钩子注册的时候定义的\n",
    "        epoch = self.trainer.epo\n",
    "        # if epoch % 3 == 0:\n",
    "        print(epoch)\n",
    "            \n",
    "            \n",
    "from torch.utils.data import DataLoader\n",
    "class EvalHook(Hook):\n",
    "    \n",
    "    def __init__(self,dataset,evaluator,period,batch_size=64):\n",
    "        \n",
    "        self.dataset=dataset\n",
    "        self.evaluator=evaluator\n",
    "        self.period=period\n",
    "        self.data_loader= DataLoader(self.dataset, batch_size=batch_size,\n",
    "                                    shuffle=False, num_workers=0,drop_last=False)\n",
    "        \n",
    "    \n",
    "    def after_epoch(self):\n",
    "        \n",
    "        epoch = self.trainer.epo\n",
    "        \n",
    "        if epoch%self.period!=0:\n",
    "            return\n",
    "        \n",
    "        model= self.trainer.model\n",
    "        model.eval()\n",
    "        self.evaluator.reset()\n",
    "        for x_batch,y_batch in self.data_loader:\n",
    "            fx_batch=model(x_batch)\n",
    "            self.evaluator.addBatch(fx_batch,model)\n",
    "            \n",
    "        return self.evaluator.get()\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "train=Trainer()\n",
    "train.register_hooks(CheckpointHook())\n",
    "train.run_train(100,12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cdae6d-c922-4aca-bab0-5af7241e0de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataLoader in module torch.utils.data.dataloader:\n",
      "\n",
      "class DataLoader(typing.Generic)\n",
      " |  DataLoader(dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[Sequence], Iterable[Sequence], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: int = 2, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |  \n",
      " |  Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      " |  the given dataset.\n",
      " |  \n",
      " |  The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      " |  iterable-style datasets with single- or multi-process loading, customizing\n",
      " |  loading order and optional automatic batching (collation) and memory pinning.\n",
      " |  \n",
      " |  See :py:mod:`torch.utils.data` documentation page for more details.\n",
      " |  \n",
      " |  Args:\n",
      " |      dataset (Dataset): dataset from which to load the data.\n",
      " |      batch_size (int, optional): how many samples per batch to load\n",
      " |          (default: ``1``).\n",
      " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      " |          at every epoch (default: ``False``).\n",
      " |      sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      " |          samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      " |          implemented. If specified, :attr:`shuffle` must not be specified.\n",
      " |      batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      " |          returns a batch of indices at a time. Mutually exclusive with\n",
      " |          :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      " |          and :attr:`drop_last`.\n",
      " |      num_workers (int, optional): how many subprocesses to use for data\n",
      " |          loading. ``0`` means that the data will be loaded in the main process.\n",
      " |          (default: ``0``)\n",
      " |      collate_fn (callable, optional): merges a list of samples to form a\n",
      " |          mini-batch of Tensor(s).  Used when using batched loading from a\n",
      " |          map-style dataset.\n",
      " |      pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      " |          into device/CUDA pinned memory before returning them.  If your data elements\n",
      " |          are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      " |          see the example below.\n",
      " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
      " |          the size of dataset is not divisible by the batch size, then the last batch\n",
      " |          will be smaller. (default: ``False``)\n",
      " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      " |          from workers. Should always be non-negative. (default: ``0``)\n",
      " |      worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
      " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      " |          input, after seeding and before data loading. (default: ``None``)\n",
      " |      generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      " |          by RandomSampler to generate random indexes and multiprocessing to generate\n",
      " |          `base_seed` for workers. (default: ``None``)\n",
      " |      prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      " |          in advance by each worker. ``2`` means there will be a total of\n",
      " |          2 * num_workers batches prefetched across all workers. (default: ``2``)\n",
      " |      persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      " |          the worker processes after a dataset has been consumed once. This allows to\n",
      " |          maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      " |      pin_memory_device (str, optional): the data loader will copy Tensors\n",
      " |          into device pinned memory before returning them if pin_memory is set to true.\n",
      " |  \n",
      " |  \n",
      " |  .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      " |               cannot be an unpicklable object, e.g., a lambda function. See\n",
      " |               :ref:`multiprocessing-best-practices` on more details related\n",
      " |               to multiprocessing in PyTorch.\n",
      " |  \n",
      " |  .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      " |               When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      " |               it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      " |               rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      " |               configurations. This represents the best guess PyTorch can make because PyTorch\n",
      " |               trusts user :attr:`dataset` code in correctly handling multi-process\n",
      " |               loading to avoid duplicate data.\n",
      " |  \n",
      " |               However, if sharding results in multiple workers having incomplete last batches,\n",
      " |               this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      " |               be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      " |               dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      " |               cases in general.\n",
      " |  \n",
      " |               See `Dataset Types`_ for more details on these two types of datasets and how\n",
      " |               :class:`~torch.utils.data.IterableDataset` interacts with\n",
      " |               `Multi-process data loading`_.\n",
      " |  \n",
      " |  .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      " |               :ref:`data-loading-randomness` notes for random seed related questions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataLoader\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[Sequence], Iterable[Sequence], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: int = 2, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self) -> '_BaseDataLoaderIter'\n",
      " |      # We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up\n",
      " |      # since '_BaseDataLoaderIter' references 'DataLoader'.\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |  \n",
      " |  __setattr__(self, attr, val)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  check_worker_number_rationality(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  multiprocessing_context\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_iterator': typing.Optional[ForwardRef('_BaseDataL...\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ae694324-40b6-4e20-9508-3b6dd3baf066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98418270-5ece-471c-9215-dc14a42bb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDD_trainer(Trainer):\n",
    "    \n",
    "    def __init__(self):       \n",
    "        self.epoches=epoches   \n",
    "        self.num_steps_per_epoch=num_steps_per_epoch  \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331066b-f458-49e5-b930-582c26a8101c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [123]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_center_c\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_loader: DataLoader, net: \u001b[43mBaseNet\u001b[49m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124;03m\"\"\"Initialize hypersphere center c as the mean from an initial forward pass on the data.\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseNet' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def init_center_c(self, train_loader: DataLoader, net: BaseNet, eps=0.1):\n",
    "    \"\"\"Initialize hypersphere center c as the mean from an initial forward pass on the data.\"\"\"\n",
    "    n_samples = 0\n",
    "    c = torch.zeros(net.rep_dim, device=self.device)\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            # get the inputs of the batch\n",
    "            inputs, _, _ = data\n",
    "            inputs = inputs.to(self.device)\n",
    "            outputs = net(inputs)\n",
    "            n_samples += outputs.shape[0]\n",
    "            c += torch.sum(outputs, dim=0)\n",
    "\n",
    "    c /= n_samples\n",
    "\n",
    "    # If c_i is too close to 0, set to +-eps. Reason: a zero unit can be trivially matched with zero weights.\n",
    "    c[(abs(c) < eps) & (c < 0)] = -eps\n",
    "    c[(abs(c) < eps) & (c > 0)] = eps\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93e0ae-1f9b-4a58-b9ed-cc8649608d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "a=[1,2,3,4]\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25126df6-cdcb-4e90-9913-41e86568b4de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdataloader\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_inf\u001b[39m():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "  \n",
    "step = 0\n",
    "num_batches = len(dataloader)\n",
    "def get_data_inf():\n",
    "    while True:\n",
    "        for out in enumerate(dataloader):\n",
    "            yield out\n",
    "dataloader_inf =  get_data_inf()\n",
    "\n",
    "\n",
    "for step in tqdm(range(epochs)):\n",
    "    epoch = int(step / 1)\n",
    "    if epoch == freeze_resnet:\n",
    "        model.unfreeze()\n",
    "\n",
    "    batch_embeds = []\n",
    "    batch_idx, data = next(dataloader_inf)\n",
    "    xs = [x.to(device) for x in data]\n",
    "    for x in xs: print(xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d360e2-0e44-4ab8-aaac-3bea3247eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SigmoidAndLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, loss_method,device):\n",
    "        super(SigmoidAndLoss, self).__init__()\n",
    "        self.loss_method=loss_method\n",
    "        self.device=device\n",
    "        assert(self.loss_method in [\"ce\",\"mse\",\"mae\"])\n",
    "\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (batch_size).\n",
    "        \"\"\"\n",
    "        if self.loss_method == \"ce\":\n",
    "            return self.ce_func(x,labels)\n",
    "        elif self.loss_method==\"mse\":\n",
    "            \n",
    "            return self.mse_func(x,labels)\n",
    "        # return loss.mean()\n",
    "\n",
    "\n",
    "    def ce_func(self,x,labels):\n",
    "        batch_size = x.size(0)\n",
    "        labels=torch.nn.functional.one_hot(labels)\n",
    "\n",
    "        x=torch.sigmoid(x).clamp(1e-6,1-(1e-6))\n",
    "        loss=-labels*torch.log(x)-(1-labels)*(torch.log(1-x))\n",
    "        return loss.mean()\n",
    "\n",
    "    def mse_func(self,x,labels):\n",
    "        \n",
    "        if not hasattr(self,\"mse\") or self.mse is None:\n",
    "            self.mse=nn.MSELoss()\n",
    "        batch_size = x.size(0)\n",
    "        labels=torch.nn.functional.one_hot(labels)\n",
    "        print(x.shape,labels.shape)\n",
    "        return self.mse(x,labels)\n",
    "\n",
    "lodd=SigmoidAndLoss(\"mse\",\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500125e-7422-4073-a90d-fd1de2bba570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5]) torch.Size([5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9290)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "ipts=torch.randn((5,5)).float()\n",
    "\n",
    "lodd(ipts,torch.tensor([1,2,3,4,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060811c-2a90-4734-b5d4-7901157c2ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using sphere_loss.....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimClrLoss(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self,device,n_views,temperature=1,**kwargs):\n",
    "        super(SimClrLoss,self).__init__()\n",
    "        self.device=device\n",
    "        self.n_views=n_views\n",
    "        self.temperature=temperature\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.device)\n",
    "        \n",
    "        self.sphere_loss=kwargs.get(\"sphere_loss\",False)        \n",
    "        if self.sphere_loss:\n",
    "            print(\"using sphere_loss.....\")\n",
    "    def info_nce_loss(self,features,batch_size):\n",
    "\n",
    "        # labels = torch.cat([torch.arange(batch_size) for i in range(n_views)], dim=0)\n",
    "        labels = torch.arange(self.n_views)\n",
    "        # labels=torch.where(labels>0,1,0)\n",
    "        labels=labels.repeat_interleave(batch_size//self.n_views)\n",
    "\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.device)\n",
    "        features = F.normalize(features, dim=1)\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        logits = similarity_matrix / self.temperature\n",
    "        return logits, labels\n",
    "    \n",
    "    \n",
    "    def info_nce_loss1(self,features,batch_size):\n",
    "\n",
    "        labels = torch.arange(self.n_views)\n",
    "        labels=torch.where(labels>0,1,0).repeat_interleave(batch_size//self.n_views) \n",
    " \n",
    "        label_mask= ((labels.unsqueeze(0) + labels.unsqueeze(1)==0)).float()\n",
    "    \n",
    "        ignore= ((labels.unsqueeze(0) + labels.unsqueeze(1)>1)).bool()\n",
    "        label_mask[ignore]=-1\n",
    "        \n",
    "        ignore = torch.eye(labels.shape[0], dtype=torch.bool)\n",
    "        label_mask[ignore]=-1\n",
    "        print(label_mask)\n",
    "        features = F.normalize(features, dim=1)\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "\n",
    "        return similarity_matrix, label_mask\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (batch_size).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        if not self.sphere_loss:\n",
    "            logits,labels=self.info_nce_loss(x,batch_size)\n",
    "            x=torch.sigmoid(logits).clamp(1e-6,1-(1e-6))\n",
    "            loss=-labels*torch.log(x)-(1-labels)*(torch.log(1-x))\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            logits,labels=self.info_nce_loss1(x,batch_size)\n",
    "            x=torch.sigmoid(logits).clamp(1e-6,1-(1e-6))\n",
    "       \n",
    "            pos_loss=-torch.log(x[labels==1])\n",
    "    \n",
    "            neg_loss=-torch.log(1-x[labels==0])\n",
    "            return pos_loss.mean()+neg_loss.mean()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "loss_fn=SimClrLoss(\"cuda\",3,1,sphere_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183ac31-8653-4200-b1cb-8b99311a9a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1., -1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  1., -1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "inputs=torch.randn((12,4)).cuda()\n",
    "\n",
    "loss=loss_fn(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262be0a-abdb-4712-b4de-89667ee9789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using sphere_loss.....\n",
      "tensor([[-1.,  1.,  1.,  1.,  0., -1., -1., -1.,  0., -1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  1., -1.,  0., -1., -1., -1.,  0., -1., -1.],\n",
      "        [ 1.,  1., -1.,  1., -1., -1.,  0., -1., -1., -1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1., -1., -1., -1.,  0., -1., -1., -1.,  0.],\n",
      "        [ 0., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1.,  0., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1.,  0., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  0., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 0., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1.,  0., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1.,  0., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  0., -1., -1., -1., -1., -1., -1., -1., -1.]])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pos_loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m+\u001b[39mneg_loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    107\u001b[0m sloss\u001b[38;5;241m=\u001b[39mSimClrLoss(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m3\u001b[39m,sphere_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 108\u001b[0m \u001b[43msloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda3/envs/torch112/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36mSimClrLoss.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     logits,labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo_nce_loss1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39msigmoid(logits)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m1e-6\u001b[39m,\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m1e-6\u001b[39m))\n\u001b[1;32m    102\u001b[0m     pos_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(x[labels\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36mSimClrLoss.info_nce_loss1\u001b[0;34m(self, features, batch_size)\u001b[0m\n\u001b[1;32m     81\u001b[0m features \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(features, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     82\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(features, features\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 83\u001b[0m label_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(label_mask)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarity_matrix, label_mask\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimClrLoss(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self,device,n_views,temperature=1,**kwargs):\n",
    "        super(SimClrLoss,self).__init__()\n",
    "        self.device=device\n",
    "        self.n_views=n_views\n",
    "        self.temperature=temperature\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.device)\n",
    "        \n",
    "        self.sphere_loss=kwargs.get(\"sphere_loss\",False)        \n",
    "        if self.sphere_loss:\n",
    "            print(\"using sphere_loss.....\")\n",
    "    def info_nce_loss(self,features,batch_size):\n",
    "\n",
    "        # labels = torch.cat([torch.arange(batch_size) for i in range(n_views)], dim=0)\n",
    "        labels = torch.arange(self.n_views)\n",
    "        # labels=torch.where(labels>0,1,0)\n",
    "        labels=labels.repeat_interleave(batch_size//self.n_views)\n",
    "\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.device)\n",
    "        features = F.normalize(features, dim=1)\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        logits = similarity_matrix / self.temperature\n",
    "        return logits, labels\n",
    "    \n",
    "    \n",
    "#     def info_nce_loss1(self,features,batch_size):\n",
    "\n",
    "#         labels = torch.arange(self.n_views)\n",
    "#         labels=torch.where(labels>0,1,0).repeat_interleave(batch_size//self.n_views) \n",
    " \n",
    "#         label_mask= ((labels.unsqueeze(0) + labels.unsqueeze(1)==0)).float()\n",
    "    \n",
    "#         ignore= ((labels.unsqueeze(0) + labels.unsqueeze(1)>1)).bool()\n",
    "#         label_mask[ignore]=-1\n",
    "        \n",
    "#         ignore = torch.eye(labels.shape[0], dtype=torch.bool)\n",
    "#         label_mask[ignore]=-1\n",
    "#         features = F.normalize(features, dim=1)\n",
    "#         similarity_matrix = torch.matmul(features, features.T)\n",
    "\n",
    "#         return similarity_matrix, label_mask\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_mask(self,n_views,batch_size):\n",
    "        def get_neg_pair_mask(n_views,batch_size):\n",
    "            labels_1D = torch.arange(batch_size//n_views).repeat(n_views) \n",
    "            masks = (labels_1D.unsqueeze(0) == labels_1D.unsqueeze(1)).bool()\n",
    "            masks[batch_size//n_views:,batch_size//n_views:]=False\n",
    "            masks[:batch_size//n_views,:batch_size//n_views:]=False\n",
    "            return masks\n",
    "\n",
    "        def get_pos_pair_mask(n_views,batch_size):\n",
    "            labels_1D = torch.arange(n_views).repeat_interleave(batch_size//n_views)     \n",
    "            masks = (labels_1D.unsqueeze(0) + labels_1D.unsqueeze(1)==0).bool()\n",
    "            return masks       \n",
    "        \n",
    "        masks=torch.ones((batch_size,batch_size)).float()*(-1)\n",
    "        masks[get_pos_pair_mask(n_views,batch_size)]=1\n",
    "        masks[get_neg_pair_mask(n_views,batch_size)]=0\n",
    "        ignore = torch.eye(batch_size,dtype=torch.bool)\n",
    "        masks[ignore]=-1\n",
    "        print(masks)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def info_nce_loss1(self,features,batch_size):\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "        similarity_matrix = torch.matmul(features, features.T).to(self.device)\n",
    "        label_mask=self.get_mask(self.n_views,batch_size).to(self.device)\n",
    "        print(label_mask)\n",
    "        return similarity_matrix, label_mask\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (batch_size).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        if not self.sphere_loss:\n",
    "            logits,labels=self.info_nce_loss(x,batch_size)\n",
    "            x=torch.sigmoid(logits).clamp(1e-6,1-(1e-6))\n",
    "            loss=-labels*torch.log(x)-(1-labels)*(torch.log(1-x))\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            logits,labels=self.info_nce_loss1(x,batch_size)\n",
    "            x=torch.sigmoid(logits).clamp(1e-6,1-(1e-6))\n",
    "       \n",
    "            pos_loss=-torch.log(x[labels==1])\n",
    "    \n",
    "            neg_loss=-torch.log(1-x[labels==0])\n",
    "            return pos_loss.mean()+neg_loss.mean()\n",
    "    \n",
    "sloss=SimClrLoss(\"cuda\",3,sphere_loss=True)\n",
    "sloss(torch.randn(12,512).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04aa6d95-b68a-4f2b-9a70-1bf582558790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0838, -0.1851,  0.7006, -0.2800, -0.5633, -1.2952,  0.6306,  0.7756,\n",
       "        -0.5537, -0.2032, -0.2340,  0.6621], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "class CosineSimilarity():\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, embeddings):\n",
    "        \n",
    "        # embeddings = F.normalize(embeddings, dim=1)\n",
    "        self.center=embeddings\n",
    "        \n",
    "    def predict(self, embeddings):\n",
    "       \n",
    "        \n",
    "        similarity_matrix = torch.matmul(embeddings, self.center.T).mean(1)\n",
    "        # print(similarity_matrix.shape)\n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    \n",
    "cs=CosineSimilarity()\n",
    "\n",
    "embeddings1=torch.randn((32,16)).cuda()\n",
    "embeddings2=torch.randn((12,16)).cuda()\n",
    "\n",
    "cs.fit(embeddings1)\n",
    "cs.predict(embeddings2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2c1b5029-3dc1-40fa-a1c9-5b2acc00c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c9709ba-c834-4e34-a052-7230c248ff1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512])\n"
     ]
    }
   ],
   "source": [
    "model=AttentionNeck(512,[256,128,1])\n",
    "inputs=torch.randn(10,512,64,64)\n",
    "\n",
    "outputs=model(inputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5ba8dec-5edc-473e-95e3-362a27d91e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_views=3\n",
    "batch_size=10\n",
    "torch.arange(n_views).repeat_interleave(batch_size//n_views) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc2b14a4-4b37-40c1-8d2b-a5aa22b0522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 124])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tensor=torch.randn((64,124))\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a427f4c-af99-4031-a5e1-063e247058ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape=(4,64//4)+tensor.shape[1:]\n",
    "new_tensor=tensor.view(new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c53d5d7-fa7f-4f30-923e-07024d25fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 248])\n"
     ]
    }
   ],
   "source": [
    "pairs1=torch.cat([new_tensor[0],new_tensor[1]],axis=1)\n",
    "print(pairs1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54bfaa58-d87f-424c-867a-d7f32d5fe45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "xs=[torch.randn(5,32)]\n",
    "y=torch.tensor([1,0,0],device=\"cpu\").float()       # loss = loss_fn(logits)\n",
    "y = y.repeat_interleave(xs[0].size(0))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3fa65e-70e1-4f8c-9b1e-12d58aff66c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init resnet from imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfsmount/shuai.lyu/Anaconda3/envs/torch112/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/nfsmount/shuai.lyu/Anaconda3/envs/torch112/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Models.models import SiameseModel\n",
    "\n",
    "pretrained=True\n",
    "head_layers=[256,256,128]\n",
    "num_classes=10\n",
    "backbone_name=\"resnet18\"\n",
    "neck_name=\"avg_pool\"\n",
    "head_name=\"mlp_head\"\n",
    "model = SiameseModel(pretrained=pretrained, head_layers=head_layers, num_classes=num_classes,\n",
    "                          backbone_name=backbone_name,neck_name=neck_name,head_name=head_name).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a67aab-a53c-40a0-b756-513989a5f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch112]",
   "language": "python",
   "name": "conda-env-torch112-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
